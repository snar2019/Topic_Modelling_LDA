{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cd564cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425088a6",
   "metadata": {},
   "source": [
    "##### Data uploading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df100453",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e52a4886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eecbbcf",
   "metadata": {},
   "source": [
    "##### Data initial exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb09a557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 568454 entries, 0 to 568453\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count   Dtype \n",
      "---  ------                  --------------   ----- \n",
      " 0   Id                      568454 non-null  int64 \n",
      " 1   ProductId               568454 non-null  object\n",
      " 2   UserId                  568454 non-null  object\n",
      " 3   ProfileName             568438 non-null  object\n",
      " 4   HelpfulnessNumerator    568454 non-null  int64 \n",
      " 5   HelpfulnessDenominator  568454 non-null  int64 \n",
      " 6   Score                   568454 non-null  int64 \n",
      " 7   Time                    568454 non-null  int64 \n",
      " 8   Summary                 568427 non-null  object\n",
      " 9   Text                    568454 non-null  object\n",
      "dtypes: int64(5), object(5)\n",
      "memory usage: 43.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbcc5e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568454, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31eb68fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                         0\n",
       "ProductId                  0\n",
       "UserId                     0\n",
       "ProfileName               16\n",
       "HelpfulnessNumerator       0\n",
       "HelpfulnessDenominator     0\n",
       "Score                      0\n",
       "Time                       0\n",
       "Summary                   27\n",
       "Text                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf366c8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>568454.000000</td>\n",
       "      <td>568454.000000</td>\n",
       "      <td>568454.00000</td>\n",
       "      <td>568454.000000</td>\n",
       "      <td>5.684540e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>284227.500000</td>\n",
       "      <td>1.743817</td>\n",
       "      <td>2.22881</td>\n",
       "      <td>4.183199</td>\n",
       "      <td>1.296257e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>164098.679298</td>\n",
       "      <td>7.636513</td>\n",
       "      <td>8.28974</td>\n",
       "      <td>1.310436</td>\n",
       "      <td>4.804331e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.393408e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>142114.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.271290e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>284227.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.311120e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>426340.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.332720e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>568454.000000</td>\n",
       "      <td>866.000000</td>\n",
       "      <td>923.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.351210e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Id  HelpfulnessNumerator  HelpfulnessDenominator  \\\n",
       "count  568454.000000         568454.000000            568454.00000   \n",
       "mean   284227.500000              1.743817                 2.22881   \n",
       "std    164098.679298              7.636513                 8.28974   \n",
       "min         1.000000              0.000000                 0.00000   \n",
       "25%    142114.250000              0.000000                 0.00000   \n",
       "50%    284227.500000              0.000000                 1.00000   \n",
       "75%    426340.750000              2.000000                 2.00000   \n",
       "max    568454.000000            866.000000               923.00000   \n",
       "\n",
       "               Score          Time  \n",
       "count  568454.000000  5.684540e+05  \n",
       "mean        4.183199  1.296257e+09  \n",
       "std         1.310436  4.804331e+07  \n",
       "min         1.000000  9.393408e+08  \n",
       "25%         4.000000  1.271290e+09  \n",
       "50%         5.000000  1.311120e+09  \n",
       "75%         5.000000  1.332720e+09  \n",
       "max         5.000000  1.351210e+09  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dad76e",
   "metadata": {},
   "source": [
    "##### Importing necessary NLTK libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18dcbe43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0025887",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\19737\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce9310a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af0a45e",
   "metadata": {},
   "source": [
    "##### text data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46ee3d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will apply Lemmatization to the Dataset \n",
    "#We are creating a function here \n",
    "\n",
    "def clean_text_data(text):\n",
    "    le = WordNetLemmatizer()\n",
    "    word_token = word_tokenize(text)\n",
    "    tokens = [le.lemmatize(x) for x in word_token if x not in stop_words and len(x)>3]\n",
    "    cleaned_text = \" \".join(tokens)\n",
    "    return cleaned_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6ed502f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying the function on the dataset\n",
    "data['cleaned_text']= data['Text'].apply(clean_text_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e1734e",
   "metadata": {},
   "source": [
    "##### TFIDF Vectorization on text columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d04f9fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "048d9114",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfvectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e0f8d6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_text = tfidfvectorizer.fit_transform(data['cleaned_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001a86f3",
   "metadata": {},
   "source": [
    "##### LDA on Vectorized text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6c35e8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "lda_model = LatentDirichletAllocation(n_components=10, learning_method='online', random_state=42, max_iter=1)\n",
    "lda_top=lda_model.fit_transform(vect_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a1ba7a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02341706, 0.0234179 , 0.02341956, 0.02341794, 0.31378355,\n",
       "        0.02342413, 0.0234194 , 0.12577401, 0.02342208, 0.39650437],\n",
       "       [0.22822555, 0.12898856, 0.02642639, 0.27171894, 0.0264333 ,\n",
       "        0.0264245 , 0.02642634, 0.02640721, 0.21250359, 0.02644563],\n",
       "       [0.02272474, 0.0226792 , 0.02267194, 0.02268252, 0.79588356,\n",
       "        0.02267184, 0.0226708 , 0.02266954, 0.0226707 , 0.02267516],\n",
       "       [0.0231176 , 0.02311831, 0.02312499, 0.02311768, 0.02312547,\n",
       "        0.02311998, 0.37114395, 0.02311714, 0.44389168, 0.0231232 ],\n",
       "       [0.02766786, 0.14364936, 0.02766968, 0.02767097, 0.02767272,\n",
       "        0.02767311, 0.02766891, 0.02767561, 0.63498248, 0.02766929]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the output\n",
    "lda_top[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5c63a5",
   "metadata": {},
   "source": [
    "##### Checking the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7aa80294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0: \n",
      "Topic  0 : 2.341706372425738 %\n",
      "Topic  1 : 2.3417900119648496 %\n",
      "Topic  2 : 2.3419556953566034 %\n",
      "Topic  3 : 2.3417941445308688 %\n",
      "Topic  4 : 31.378354750706972 %\n",
      "Topic  5 : 2.342413439889342 %\n",
      "Topic  6 : 2.341939902452953 %\n",
      "Topic  7 : 12.577400802225464 %\n",
      "Topic  8 : 2.3422083355725616 %\n",
      "Topic  9 : 39.65043654487465 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Document 0: \")\n",
    "for i,topic in enumerate(lda_top[0]):\n",
    "    print(\"Topic \",i,\":\",topic*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9fa609",
   "metadata": {},
   "source": [
    "##### Analyzing the topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "dbd50837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: \n",
      "treat dog chew training grain jerky teeth beef love salmon Topic 1: \n",
      "peanut chocolate butter bar candy love snack cracker yummy almond Topic 2: \n",
      "coffee flavor taste like good strong cup green drink dark Topic 3: \n",
      "hair ball soft puppy cake bread skin filling morning oatmeal Topic 4: \n",
      "chip like taste good flavor great cooky salt snack love Topic 5: \n",
      "amazon price product shipping store great order love good time Topic 6: \n",
      "sugar water coconut drink taste product com like bottle chai Topic 7: \n",
      "sauce store local grocery raisin amazon awesome online buying price Topic 8: \n",
      "arrived quickly gift order delivery product ordered received great thanks Topic 9: \n",
      "food love like product cat good year time baby really "
     ]
    }
   ],
   "source": [
    "#Let us check what are the top words that comprise the topics. \n",
    "#This would give us a view of what defines each of these topics.\n",
    "\n",
    "vocab = tfidfvectorizer.get_feature_names()\n",
    "for i, comp in enumerate(lda_model.components_):\n",
    "     vocab_comp = zip(vocab, comp)\n",
    "     sorted_words = sorted(vocab_comp, key= lambda x:x[1], reverse=True)[:10]\n",
    "     print(\"Topic \"+str(i)+\": \")\n",
    "     for t in sorted_words:\n",
    "            print(t[0], end=\" \")\n",
    "           \n",
    "            \n",
    "            \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46de41d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
